{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full. my_tk import My_tokenizer\n",
    "from ipynb.fs.full. config import Config\n",
    "from ipynb.fs.full. utils_data import DLoader\n",
    "from ipynb.fs.full. utils_func import *\n",
    "from ipynb.fs.full. model_ino import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, config:Config, device:torch.device, mode:str, continuous:int):\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        self.mode = mode\n",
    "        self.continuous = continuous\n",
    "        self.dataloaders = {}\n",
    "\n",
    "        # if continuous, load previous training info\n",
    "        if self.continuous:\n",
    "            with open(self.config.loss_data_path, 'rb') as f:\n",
    "                self.loss_data = pickle.load(f)\n",
    "\n",
    "        # path, data params\n",
    "        self.base_path = self.config.base_path\n",
    "        self.model_path = self.config.model_path\n",
    "\n",
    "        # train params\n",
    "        self.batch_size = self.config.batch_size\n",
    "        self.epochs = self.config.epochs\n",
    "        self.enc_lr = self.config.enc_lr\n",
    "        self.dec_lr = self.config.dec_lr\n",
    "\n",
    "        # model params\n",
    "        self.img_size = self.config.img_size\n",
    "        self.max_len = self.config.max_len\n",
    "\n",
    "        # for reproducibility\n",
    "        torch.manual_seed(999)\n",
    "\n",
    "        # set transforms (ImageNet mean, std because pre-trained ResNet101 trained by ImageNet)\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        self.trans = transforms.Compose([\n",
    "            transforms.Resize((self.img_size, self.img_size)), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)])\n",
    "\n",
    "        # make dataset\n",
    "        self.img_folder = self.base_path + 'data/Images/'\n",
    "        self.caption_file = self.base_path + 'data/captions.txt'\n",
    "        self.all_pairs = collect_all_pairs(self.caption_file)\n",
    "        \n",
    "        # 편의상 500개 사용 \n",
    "        self.all_pairs = self.all_pairs[:500]\n",
    "        self.trainset_id, self.valset_id = make_dataset_ids(len(self.all_pairs), 100)\n",
    "        self.tokenizer = My_tokenizer(self.config, self.all_pairs, self.trainset_id)\n",
    "\n",
    "        # train set\n",
    "        if self.mode == 'train':\n",
    "            self.trainset = DLoader(self.img_folder, self.all_pairs, self.trans, self.trainset_id, self.tokenizer, self.max_len)\n",
    "            self.dataloaders['train'] = DataLoader(self.trainset, batch_size=self.batch_size, shuffle=True, num_workers=8)\n",
    "        \n",
    "        # val set\n",
    "        self.valset = DLoader(self.img_folder, self.all_pairs, self.trans, self.valset_id, self.tokenizer, self.max_len)\n",
    "        self.dataloaders['test'] = DataLoader(self.valset, batch_size=self.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "        # model, optimizer, loss\n",
    "        self.encoder = Encoder(self.config).to(self.device)\n",
    "        self.decoder = Decoder(self.config, self.tokenizer).to(self.device)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
    "\n",
    "        # 훈련시킬 경우 -> 옵티마이저, 러닝레이트 필요\n",
    "        if self.mode == 'train':\n",
    "            # encoder, decoder optimizer 설정\n",
    "            self.enc_optimizer = optim.Adam(params=filter(lambda p: p.requires_grad, self.encoder.parameters()), lr=self.enc_lr)\n",
    "            self.dec_optimizer = optim.Adam(self.decoder.parameters(), lr=self.dec_lr)\n",
    "\n",
    "            # 이어서 학습할 경우\n",
    "            if self.continuous:\n",
    "                self.check_point = torch.load(self.model_path, map_location=self.device)\n",
    "                self.encoder.load_state_dict(self.check_point['model']['encoder'])\n",
    "                self.decoder.load_state_dict(self.check_point['model']['decoder'])\n",
    "                self.enc_optimizer.load_state_dict(self.check_point['optimizer']['encoder'])\n",
    "                self.dec_optimizer.load_state_dict(self.check_point['optimizer']['decoder'])\n",
    "                del self.check_point\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        # 테스트, 추론할 경우\n",
    "        elif self.mode == 'test' or self.mode == 'inference':\n",
    "            self.trans4attn = transforms.Compose([\n",
    "                transforms.Resize((252, 252)),\n",
    "                transforms.ToTensor()])\n",
    "            self.check_point = torch.load(self.model_path, map_location=self.device)\n",
    "            self.encoder.load_state_dict(self.check_point['model']['encoder'])\n",
    "            self.decoder.load_state_dict(self.check_point['model']['decoder'])\n",
    "            self.encoder.eval()\n",
    "            self.decoder.eval()\n",
    "            del self.check_point\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "    def train(self):\n",
    "        early_stop = 0\n",
    "        # 사전 학습이 되있으면 loss_data에서 가져옴, 아니면 새로 선언\n",
    "        best_val_bleu = 0 if not self.continuous else self.loss_data['best_val_bleu']\n",
    "        train_loss_history = [] if not self.continuous else self.loss_data['train_loss_history']\n",
    "        val_loss_history = [] if not self.continuous else self.loss_data['val_loss_history']\n",
    "        val_score_history = {'bleu2': [], 'bleu4': [], 'nist2': [], 'nist4': [], 'topk_acc': []} if not self.continuous else self.loss_data['val_score_history']\n",
    "        best_epoch_info = 0 if not self.continuous else self.loss_data['best_epoch']\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            start = time.time()\n",
    "            print(epoch + 1, '/', self.epochs)\n",
    "            print('-'*10)\n",
    "            for phase in ['train', 'test']:\n",
    "                print('Phase: {}'.format(phase))\n",
    "\n",
    "                if phase == 'train':    # train인 경우\n",
    "                    self.encoder.train()\n",
    "                    self.decoder.train()\n",
    "                else:                   # test인 경우\n",
    "                    self.encoder.eval()\n",
    "                    self.decoder.eval()\n",
    "\n",
    "                total_loss, total_acc = 0, 0\n",
    "                all_val_trg, all_val_output = [], []\n",
    "                \n",
    "                for i, (img, cap, _) in enumerate(self.dataloaders[phase]):\n",
    "                    batch_size = img.size(0)\n",
    "                    print('in train, line 121')\n",
    "                    print(type(batch_size))\n",
    "                    print(type(img.size))\n",
    "                    print(img.size(0))\n",
    "                    \n",
    "                    img, cap = img.to(self.device), cap.to(self.device)\n",
    "                    self.enc_optimizer.zero_grad()\n",
    "                    self.dec_optimizer.zero_grad()\n",
    "\n",
    "                    # train이면 grad 변화\n",
    "                    with torch.set_grad_enabled(phase=='train'):\n",
    "                        enc_output, hidden = self.encoder(img)\n",
    "                        \n",
    "                        decoder_all_output, decoder_all_score = [], []\n",
    "                        for j in range(self.max_len):\n",
    "                            trg_word = cap[:, j].unsqueeze(1)\n",
    "                            print('aaaaaa')\n",
    "                            dec_output, hidden, score = self.decoder(trg_word, hidden, enc_output)\n",
    "                            decoder_all_output.append(dec_output)\n",
    "                            \n",
    "                            # Attention layer면\n",
    "                            if self.config.is_attn:\n",
    "                                decoder_all_score.append(score)\n",
    "\n",
    "                        print('cex')\n",
    "                        decoder_all_output = torch.cat(decoder_all_output, dim= 1)\n",
    "\n",
    "                        loss = self.criterion(decoder_all_output[:, :-1, :].reshape(-1, decoder_all_output.size(-1)), cap[:, 1:].reshape(-1))\n",
    "\n",
    "                        if self.config.is_attn:\n",
    "                            decoder_all_score = torch.cat(decoder_all_score, dim=2)\n",
    "                            loss += self.config.regularization_lambda * ((1. - torch.sum(decoder_all_score, dim=2)) ** 2).mean()\n",
    "                        \n",
    "                        acc = topk_accuracy(decoder_all_output[:, :-1, :], cap[:, 1:], self.config.topk, self.tokenizer.eos_token_id)\n",
    "                        \n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            self.enc_optimizer.step()\n",
    "                            self.dec_optimizer.step()\n",
    "                        else:\n",
    "                            all_val_trg.append(cap.detach().cpu())\n",
    "                            all_val_output.append(decoder_all_output.detach().cpu())\n",
    "\n",
    "                    total_loss += loss.item()*batch_size\n",
    "                    total_acc += acc * batch_size\n",
    "\n",
    "                    if i % 100 == 0:\n",
    "                        print('Epoch {}: {}/{} step loss: {}, top-{} acc: {}'.format(epoch+1, i, len(self.dataloaders[phase]), loss.item(), self.config.topk, acc))\n",
    "\n",
    "                epoch_loss = total_loss/len(self.dataloaders[phase].dataset)\n",
    "                epoch_acc = total_acc/len(self.dataloaders[phase].dataset)\n",
    "                print('{} loss: {:4f}, top-{} acc: {:4f}\\n'.format(phase, epoch_loss, self.config.topk, epoch_acc))\n",
    "\n",
    "                if phase == 'train':\n",
    "                    train_loss_history.append(epoch_loss)\n",
    "                if phase == 'test':\n",
    "                    val_loss_history.append(epoch_loss)\n",
    "\n",
    "                    # print examples\n",
    "                    print_samples(cap, decoder_all_output, self.tokenizer)\n",
    "\n",
    "                    # calculate scores\n",
    "                    all_val_trg, all_val_output = tensor2list(all_val_trg, all_val_output, self.tokenizer)\n",
    "                    val_score_history['bleu2'].append(cal_scores(all_val_trg, all_val_output, 'bleu', 2))\n",
    "                    val_score_history['bleu4'].append(cal_scores(all_val_trg, all_val_output, 'bleu', 4))\n",
    "                    val_score_history['nist2'].append(cal_scores(all_val_trg, all_val_output, 'nist', 2))\n",
    "                    val_score_history['nist4'].append(cal_scores(all_val_trg, all_val_output, 'nist', 4))\n",
    "                    val_score_history['topk_acc'].append(epoch_acc)\n",
    "                    print('bleu2: {}, bleu4: {}, nist2: {}, nist4: {}'.format(val_score_history['bleu2'][-1], val_score_history['bleu4'][-1], val_score_history['nist2'][-1], val_score_history['nist4'][-1]))\n",
    "                    \n",
    "                    # save best model\n",
    "                    early_stop += 1\n",
    "                    if best_val_bleu < val_score_history['bleu4'][-1]:\n",
    "                        early_stop = 0\n",
    "                        best_val_bleu = val_score_history['bleu4'][-1]\n",
    "                        best_enc_wts = copy.deepcopy(self.encoder.state_dict())\n",
    "                        best_dec_wts = copy.deepcopy(self.decoder.state_dict())\n",
    "                        best_epoch = best_epoch_info + epoch + 1\n",
    "                        save_checkpoint(self.model_path, [self.encoder, self.decoder], [self.enc_optimizer, self.dec_optimizer])\n",
    "\n",
    "            print(\"time: {} s\\n\".format(time.time() - start))\n",
    "            print('\\n'*2)\n",
    "\n",
    "            # early stopping\n",
    "            if early_stop == self.config.early_stop_criterion:\n",
    "                break\n",
    "\n",
    "        print('best val bleu: {:4f}, best epoch: {:d}\\n'.format(best_val_bleu, best_epoch))\n",
    "        self.model = {'encoder': self.encoder.load_state_dict(best_enc_wts), 'decoder': self.decoder.load_state_dict(best_dec_wts)}\n",
    "        self.loss_data = {'best_epoch': best_epoch, 'best_val_bleu': best_val_bleu, 'train_loss_history': train_loss_history, 'val_loss_history': val_loss_history, 'val_score_history': val_score_history}\n",
    "        return self.model, self.loss_data\n",
    "    \n",
    "\n",
    "    def test(self):        \n",
    "        # statistics of the test set\n",
    "        phase = 'test'\n",
    "        total_loss = 0\n",
    "        all_val_trg, all_val_output, all_val_score = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.encoder.eval()\n",
    "            self.decoder.eval()\n",
    "\n",
    "            for img, cap, _ in self.dataloaders[phase]:\n",
    "                batch = img.size(0)\n",
    "                img, cap = img.to(self.device), cap.to(self.device)\n",
    "                enc_output, hidden = self.encoder(img)\n",
    "                \n",
    "                decoder_all_output, decoder_all_score = [], []\n",
    "                for j in range(self.max_len):\n",
    "                    trg_word = cap[:, j].unsqueeze(1)\n",
    "                    dec_output, hidden, score = self.decoder(trg_word, hidden, enc_output)\n",
    "                    decoder_all_output.append(dec_output)\n",
    "                    if self.config.is_attn:\n",
    "                        decoder_all_score.append(score)\n",
    "\n",
    "                decoder_all_output = torch.cat(decoder_all_output, dim=1)\n",
    "                if self.config.is_attn:\n",
    "                    decoder_all_score = torch.cat(decoder_all_score, dim=2)\n",
    "\n",
    "                loss = self.criterion(decoder_all_output[:, :-1, :].reshape(-1, decoder_all_output.size(-1)), cap[:, 1:].reshape(-1))\n",
    "                loss += self.config.regularization_lambda * ((1. - torch.sum(decoder_all_score, dim=2)) ** 2).mean()\n",
    "                \n",
    "                all_val_trg.append(cap.detach().cpu())\n",
    "                all_val_output.append(decoder_all_output.detach().cpu())\n",
    "                if self.config.is_attn:\n",
    "                    all_val_score.append(decoder_all_score.detach().cpu())\n",
    "\n",
    "                total_loss += loss.item()*batch\n",
    "\n",
    "        # calculate loss and ppl\n",
    "        total_loss = total_loss / len(self.dataloaders[phase].dataset)\n",
    "        print('loss: {}, ppl: {}'.format(total_loss, np.exp(total_loss)))\n",
    "\n",
    "        # calculate scores\n",
    "        all_val_trg_l, all_val_output_l = tensor2list(all_val_trg, all_val_output, self.tokenizer)\n",
    "        bleu2 = cal_scores(all_val_trg_l, all_val_output_l, 'bleu', 2)\n",
    "        bleu4 = cal_scores(all_val_trg_l, all_val_output_l, 'bleu', 4)\n",
    "        nist2 = cal_scores(all_val_trg_l, all_val_output_l, 'nist', 2)\n",
    "        nist4 = cal_scores(all_val_trg_l, all_val_output_l, 'nist', 4)\n",
    "        print('bleu2: {}, bleu4: {}, nist2: {}, nist4: {}'.format(bleu2, bleu4, nist2, nist4))\n",
    "\n",
    "\n",
    "    def inference(self, result_num, model_name):\n",
    "        if result_num > len(self.dataloaders['test'].dataset):\n",
    "            print('The number of results that you want to see are larger than total test set')\n",
    "            sys.exit()\n",
    "        \n",
    "        # statistics of IMDb test set\n",
    "        phase = 'test'\n",
    "        total_loss = 0\n",
    "        all_val_trg, all_val_output, all_val_score = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.encoder.eval()\n",
    "            self.decoder.eval()\n",
    "            all_ids = []\n",
    "\n",
    "            for img, cap, id in self.dataloaders[phase]:\n",
    "                all_ids.append(id.cpu())\n",
    "                batch = img.size(0)\n",
    "                img, cap = img.to(self.device), cap.to(self.device)\n",
    "                enc_output, hidden = self.encoder(img)\n",
    "                \n",
    "                decoder_all_output, decoder_all_score = [], []\n",
    "                for j in range(self.max_len):\n",
    "                    if j == 0:\n",
    "                        trg_word = cap[:, j].unsqueeze(1)\n",
    "                        dec_output, hidden, score = self.decoder(trg_word, hidden, enc_output)\n",
    "                    else:\n",
    "                        trg_word = torch.argmax(dec_output, dim=-1)\n",
    "                        dec_output, hidden, score = self.decoder(trg_word.detach(), hidden, enc_output)\n",
    "                    \n",
    "                    decoder_all_output.append(dec_output)\n",
    "                    if self.config.is_attn:\n",
    "                        decoder_all_score.append(score)\n",
    "\n",
    "                decoder_all_output = torch.cat(decoder_all_output, dim=1)\n",
    "                if self.config.is_attn:\n",
    "                    decoder_all_score = torch.cat(decoder_all_score, dim=2)\n",
    "\n",
    "                loss = self.criterion(decoder_all_output[:, :-1, :].reshape(-1, decoder_all_output.size(-1)), cap[:, 1:].reshape(-1))\n",
    "                loss += self.config.regularization_lambda * ((1. - torch.sum(decoder_all_score, dim=2)) ** 2).mean()\n",
    "                \n",
    "                all_val_trg.append(cap.detach().cpu())\n",
    "                all_val_output.append(decoder_all_output.detach().cpu())\n",
    "                if self.config.is_attn:\n",
    "                    all_val_score.append(decoder_all_score.detach().cpu())\n",
    "\n",
    "                total_loss += loss.item()*batch\n",
    "            all_ids = torch.cat(all_ids, dim=0).tolist()\n",
    "\n",
    "        # calculate loss and ppl\n",
    "        total_loss = total_loss / len(self.dataloaders[phase].dataset)\n",
    "        print('Inference Score')\n",
    "        print('loss: {}, ppl: {}'.format(total_loss, np.exp(total_loss)))\n",
    "\n",
    "        # calculate scores\n",
    "        all_val_trg_l, all_val_output_l = tensor2list(all_val_trg, all_val_output, self.tokenizer)\n",
    "        bleu2 = cal_scores(all_val_trg_l, all_val_output_l, 'bleu', 2)\n",
    "        bleu4 = cal_scores(all_val_trg_l, all_val_output_l, 'bleu', 4)\n",
    "        nist2 = cal_scores(all_val_trg_l, all_val_output_l, 'nist', 2)\n",
    "        nist4 = cal_scores(all_val_trg_l, all_val_output_l, 'nist', 4)\n",
    "        print('\\nInference Score')\n",
    "        print('bleu2: {}, bleu4: {}, nist2: {}, nist4: {}\\n\\n'.format(bleu2, bleu4, nist2, nist4))\n",
    "\n",
    "        # show results examples\n",
    "        random.seed(int(1000*time.time())%(2**32))\n",
    "        all_val_trg = torch.cat(all_val_trg, dim=0)\n",
    "        all_val_output = torch.argmax(torch.cat(all_val_output, dim=0), dim=2)\n",
    "        ids = random.sample(list(range(all_val_trg.size(0))), 10)\n",
    "        img_id = [self.img_folder+self.all_pairs[j][0] for j in [all_ids[i] for i in ids]]\n",
    "        gt, pred = print_samples(all_val_trg, all_val_output, self.tokenizer, result_num, ids)\n",
    "        if self.config.is_attn:\n",
    "            all_val_score = torch.cat(all_val_score, dim=0)\n",
    "            pred_l = [len(self.tokenizer.tokenize(s)) for s in pred]\n",
    "            attn_img = [all_val_score[i, :, :l] for i, l in zip(ids, pred_l)]\n",
    "\n",
    "        # save result figures\n",
    "        results_save_path = self.base_path + 'result/' + model_name + '/'\n",
    "        save_figures(img_id, gt, pred, results_save_path)\n",
    "        if self.config.is_attn:\n",
    "            save_attn_figures(img_id, attn_img, pred, results_save_path, self.trans4attn, self.config.enc_hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
