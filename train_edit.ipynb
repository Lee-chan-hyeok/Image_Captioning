{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] 지정된 모듈을 찾을 수 없습니다. Error loading \"C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\__init__.py:141\u001b[0m\n\u001b[0;32m    139\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    140\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 141\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    143\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] 지정된 모듈을 찾을 수 없습니다. Error loading \"C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full. my_tk import My_tokenizer\n",
    "from ipynb.fs.full. config import Config\n",
    "from ipynb.fs.full. utils_data import DLoader\n",
    "from ipynb.fs.full. utils_func import *\n",
    "from ipynb.fs.full. model_ino import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, config:Config, device:torch.device, mode:str, continuous:int):\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        self.mode = mode\n",
    "        self.continuous = continuous\n",
    "        self.dataloaders = {}\n",
    "\n",
    "        self.model = {}\n",
    "        self.loss_data = {}\n",
    "\n",
    "        # if continuous, load previous training info\n",
    "        if self.continuous:\n",
    "            with open(self.config.loss_data_path, 'rb') as f:\n",
    "                self.loss_data = pickle.load(f)\n",
    "\n",
    "        # path, data params\n",
    "        self.base_path = self.config.base_path\n",
    "        self.model_path = self.config.model_path\n",
    "\n",
    "        # train params\n",
    "        self.batch_size = self.config.batch_size\n",
    "        self.epochs = self.config.epochs\n",
    "        self.enc_lr = self.config.enc_lr\n",
    "        self.dec_lr = self.config.dec_lr\n",
    "\n",
    "        # model params\n",
    "        self.img_size = self.config.img_size\n",
    "        self.max_len = self.config.max_len\n",
    "\n",
    "        # for reproducibility\n",
    "        torch.manual_seed(999)\n",
    "\n",
    "        # set transforms (ImageNet mean, std because pre-trained ResNet101 trained by ImageNet)\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        self.trans = transforms.Compose([\n",
    "            transforms.Resize((self.img_size, self.img_size)), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)])\n",
    "\n",
    "        # make dataset\n",
    "        self.img_folder = self.base_path + 'data/Images/'\n",
    "        self.caption_file = self.base_path + 'data/captions.txt'\n",
    "        self.all_pairs = collect_all_pairs(self.caption_file)\n",
    "        \n",
    "        # 편의상 400개까지\n",
    "        self.all_pairs = self.all_pairs[:74]\n",
    "        self.trainset_id, self.valset_id = make_dataset_ids(len(self.all_pairs), 10)\n",
    "        self.tokenizer = My_tokenizer(self.config, self.all_pairs, self.trainset_id)\n",
    "\n",
    "        # train set\n",
    "        if self.mode == 'train':\n",
    "            self.trainset = DLoader(self.img_folder, self.all_pairs, self.trans, self.trainset_id, self.tokenizer, self.max_len)\n",
    "            self.dataloaders['train'] = DataLoader(self.trainset, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "        \n",
    "        # val set\n",
    "        self.valset = DLoader(self.img_folder, self.all_pairs, self.trans, self.valset_id, self.tokenizer, self.max_len)\n",
    "        self.dataloaders['test'] = DataLoader(self.valset, batch_size=self.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "        # model, optimizer, loss\n",
    "        self.encoder = Encoder(self.config).to(self.device)\n",
    "        self.decoder = Decoder(self.config, self.tokenizer).to(self.device)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
    "\n",
    "        # 훈련시킬 경우 -> 옵티마이저, 러닝레이트 필요\n",
    "        if self.mode == 'train':\n",
    "            # encoder, decoder optimizer 설정\n",
    "            self.enc_optimizer = optim.Adam(params=filter(lambda p: p.requires_grad, self.encoder.parameters()), lr=self.enc_lr)\n",
    "            self.dec_optimizer = optim.Adam(self.decoder.parameters(), lr=self.dec_lr)\n",
    "\n",
    "            # 이어서 학습할 경우\n",
    "            if self.continuous:\n",
    "                self.check_point = torch.load(self.model_path, map_location=self.device)\n",
    "                self.encoder.load_state_dict(self.check_point['model']['encoder'])\n",
    "                self.decoder.load_state_dict(self.check_point['model']['decoder'])\n",
    "                self.enc_optimizer.load_state_dict(self.check_point['optimizer']['encoder'])\n",
    "                self.dec_optimizer.load_state_dict(self.check_point['optimizer']['decoder'])\n",
    "                del self.check_point\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # 테스트, 추론할 경우\n",
    "        elif self.mode == 'test' or self.mode == 'inference':\n",
    "            self.trans4attn = transforms.Compose([\n",
    "                transforms.Resize((252, 252)),\n",
    "                transforms.ToTensor()])\n",
    "            self.check_point = torch.load(self.model_path, map_location=self.device)\n",
    "            self.encoder.load_state_dict(self.check_point['model']['encoder'])\n",
    "            self.decoder.load_state_dict(self.check_point['model']['decoder'])\n",
    "            self.encoder.eval()\n",
    "            self.decoder.eval()\n",
    "            del self.check_point\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(Trainer):\n",
    "    early_stop = 0\n",
    "\n",
    "    # 사전학습 유무\n",
    "    best_val_bleu = 0 if not Trainer.continuous else Trainer.loss_data['best_val_bleu']\n",
    "    train_loss_history = [] if not Trainer.continuous else Trainer.loss_data['train_loss_history']\n",
    "    val_loss_history = [] if not Trainer.continuous else Trainer.loss_data['val_loss_history']\n",
    "    val_score_history = {'bleu2': [], 'bleu4': [], 'nist2': [], 'nist4': [], 'topk_acc': []} if not Trainer.continuous else Trainer.loss_data['val_score_history']\n",
    "    best_epoch_info = 0 if not Trainer.continuous else Trainer.loss_data['best_epoch']\n",
    "\n",
    "    for epoch in range(Trainer.epochs):\n",
    "        print('*'*10, 'epoch start', '*'*10)\n",
    "        start = time.time() # epoch 시작\n",
    "        print(epoch + 1, '/', Trainer.epochs)\n",
    "        print('-'*10)\n",
    "\n",
    "        for phase in ['train', 'test']:\n",
    "            print('Phase: {}'.format(phase))\n",
    "\n",
    "            if phase == 'train':    # train인 경우\n",
    "                Trainer.encoder.train()\n",
    "                Trainer.decoder.train()\n",
    "            else:                   # test인 경우\n",
    "                Trainer.encoder.eval()\n",
    "                Trainer.decoder.eval()\n",
    "\n",
    "            total_loss, total_acc = 0, 0\n",
    "            all_val_trg, all_val_output = [], []\n",
    "\n",
    "            print('-'*20, 'enumer start', '-'*20)\n",
    "            for i, (img, cap, _) in enumerate(Trainer.dataloaders[phase]):\n",
    "\n",
    "                batch_size = img.size(0)\n",
    "                #print('in train_model, line 32')\n",
    "                #print('shape = ', img.shape)\n",
    "                \n",
    "                img, cap = img.to(Trainer.device), cap.to(Trainer.device)\n",
    "                Trainer.enc_optimizer.zero_grad()\n",
    "                Trainer.dec_optimizer.zero_grad()\n",
    "\n",
    "                # train이면 grad 변화\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    enc_output, hidden = Trainer.encoder(img)\n",
    "                    \n",
    "                    decoder_all_output, decoder_all_score = [], []\n",
    "\n",
    "                    #print('line 45, max_len = ', Trainer.max_len)\n",
    "                    \n",
    "                    for j in range(Trainer.max_len):\n",
    "                        trg_word = cap[:, j].unsqueeze(1)\n",
    "                        dec_output, hidden, score = Trainer.decoder(trg_word, hidden, enc_output)\n",
    "                        #print('decoding')\n",
    "                        decoder_all_output.append(dec_output)\n",
    "                        #print('append')\n",
    "                        \n",
    "                        # Attention layer면\n",
    "                        if Trainer.config.is_attn:\n",
    "                            #print('into append')\n",
    "                            decoder_all_score.append(score)\n",
    "                            #print('if append')\n",
    "\n",
    "                    decoder_all_output = torch.cat(decoder_all_output, dim= 1)\n",
    "                    print('line 60, decoder all output', decoder_all_output.shape)\n",
    "\n",
    "                    loss = Trainer.criterion(decoder_all_output[:, :-1, :].reshape(-1, decoder_all_output.size(-1)), cap[:, 1:].reshape(-1))\n",
    "                    print('line 63, loss is', loss)\n",
    "\n",
    "                    if Trainer.config.is_attn:\n",
    "                        decoder_all_score = torch.cat(decoder_all_score, dim=2)\n",
    "                        loss += Trainer.config.regularization_lambda * ((1. - torch.sum(decoder_all_score, dim=2)) ** 2).mean()\n",
    "                    \n",
    "                    acc = topk_accuracy(decoder_all_output[:, :-1, :], cap[:, 1:], Trainer.config.topk, Trainer.tokenizer.eos_token_id)\n",
    "                    print('line 71, acc', acc)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        Trainer.enc_optimizer.step()\n",
    "                        Trainer.dec_optimizer.step()\n",
    "                    else:\n",
    "                        all_val_trg.append(cap.detach().cpu())\n",
    "                        all_val_output.append(decoder_all_output.detach().cpu())\n",
    "\n",
    "                total_loss += loss.item()*batch_size\n",
    "                total_acc += acc * batch_size\n",
    "                print(f'total_loss is {total_loss}, total_acc is {total_acc}')\n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    print('Epoch {}: {}/{} step loss: {}, top-{} acc: {}'.format(epoch+1, i, len(Trainer.dataloaders[phase]), loss.item(), Trainer.config.topk, acc))\n",
    "                \n",
    "            print('-'*20, 'enumer end', '-'*20)\n",
    "\n",
    "            epoch_loss = total_loss/len(Trainer.dataloaders[phase].dataset)\n",
    "            epoch_acc = total_acc/len(Trainer.dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase} loss: {epoch_loss}, top-{Trainer.config.topk} acc: {epoch_acc}\\n')\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_loss_history.append(epoch_loss)\n",
    "            if phase == 'test':\n",
    "                val_loss_history.append(epoch_loss)\n",
    "\n",
    "                # print examples\n",
    "                print_samples(cap, decoder_all_output, Trainer.tokenizer)\n",
    "                print('line 100, print sample done..')\n",
    "\n",
    "                # calculate scores\n",
    "                all_val_trg, all_val_output = tensor2list(all_val_trg, all_val_output, Trainer.tokenizer)\n",
    "                print('tensor2list done')\n",
    "                print(type(all_val_trg))\n",
    "                print(all_val_trg)\n",
    "                # val_score_history['bleu2'].append(cal_scores(all_val_trg, all_val_output, 'bleu', 2))\n",
    "                print('blew2 append done')\n",
    "                # val_score_history['bleu4'].append(cal_scores(all_val_trg, all_val_output, 'bleu', 4))\n",
    "                print('blew4 append done')\n",
    "                val_score_history['nist2'].append(cal_scores(all_val_trg, all_val_output, 'nist', 2))\n",
    "                print('nist2 append done')\n",
    "                val_score_history['nist4'].append(cal_scores(all_val_trg, all_val_output, 'nist', 4))\n",
    "                print('nist4 append done')\n",
    "                val_score_history['topk_acc'].append(epoch_acc)\n",
    "                print('topk acc append done')\n",
    "\n",
    "                print('bleu2: {}, bleu4: {}, nist2: {}, nist4: {}'.format(val_score_history['bleu2'][-1], val_score_history['bleu4'][-1], val_score_history['nist2'][-1], val_score_history['nist4'][-1]))\n",
    "                print('line 110, cal scores done')\n",
    "                    \n",
    "                # save best model\n",
    "                early_stop += 1\n",
    "\n",
    "                if best_val_bleu < val_score_history['bleu4'][-1]: # 마지막 score가 더 높으면\n",
    "                    early_stop = 0\n",
    "                    # best_val 변경\n",
    "                    best_val_bleu = val_score_history['bleu4'][-1]\n",
    "                    # encoder, decorder weights 변경\n",
    "                    best_enc_wts = copy.deepcopy(Trainer.encoder.state_dict())\n",
    "                    best_dec_wts = copy.deepcopy(Trainer.decoder.state_dict())\n",
    "                    # best epoch 변경\n",
    "                    best_epoch = best_epoch_info + epoch + 1\n",
    "                    # 저장\n",
    "                    save_checkpoint(Trainer.model_path, [Trainer.encoder, Trainer.decoder], [Trainer.enc_optimizer, Trainer.dec_optimizer])\n",
    "        print('*'*10, 'epoch end', '*'*10)\n",
    "                    \n",
    "        print(\"time: {} s\\n\".format(time.time() - start)) # epoch 끝\n",
    "        print('\\n'*2)\n",
    "\n",
    "        # early stopping\n",
    "        if early_stop == Trainer.config.early_stop_criterion:\n",
    "                break\n",
    "\n",
    "    # best 값 출력\n",
    "    print('best val bleu: {:4f}, best epoch: {:d}\\n'.format(best_val_bleu, best_epoch))\n",
    "\n",
    "    # model을 딕셔너리로\n",
    "    Trainer.model = {'encoder': Trainer.encoder.load_state_dict(best_enc_wts), 'decoder': Trainer.decoder.load_state_dict(best_dec_wts)}\n",
    "    Trainer.loss_data = {'best_epoch': best_epoch, 'best_val_bleu': best_val_bleu, 'train_loss_history': train_loss_history, 'val_loss_history': val_loss_history, 'val_score_history': val_score_history}\n",
    "\n",
    "    return Trainer.model, Trainer.loss_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
