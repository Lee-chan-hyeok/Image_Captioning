{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:97: SyntaxWarning: invalid escape sequence '\\-'\n",
      "<>:97: SyntaxWarning: invalid escape sequence '\\-'\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_3996\\713752974.py:97: SyntaxWarning: invalid escape sequence '\\-'\n",
      "  s = re.sub('[#$%&()*+\\-/:;<=>@\\[\\]^_`{|}~\\'\".,?!]', '', s).lower()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.nist_score import corpus_nist\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import skimage.transform\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(file, model, optimizer):\n",
    "    state = {'model': {'encoder':model[0].state_dict(), 'decoder': model[1].state_dict()}, 'optimizer': {'encoder':optimizer[0].state_dict(), 'decoder': optimizer[1].state_dict()}}\n",
    "    torch.save(state, file)\n",
    "    print('model pt file is being saved\\n')\n",
    "\n",
    "\n",
    "def print_samples(trg, output, tokenizer, show_n=3, idx=None):\n",
    "    all_t, all_o = [], []\n",
    "    trg, output = trg.detach().cpu(), output.detach().cpu()\n",
    "    if idx == None:\n",
    "        idx = random.sample(list(range(trg.size(0))), show_n)\n",
    "        print('-'*50)\n",
    "        for i in idx:\n",
    "            t, o = trg[i, 1:].tolist(), torch.argmax(output[i, :-1], dim=1).tolist()\n",
    "            t, o = tokenizer.decode(t), tokenizer.decode(o)\n",
    "            t, o = ' '.join(t.split()), ' '.join(o.split())\n",
    "            print('gt  : {}'.format(t))\n",
    "            print('pred: {}\\n'.format(o))\n",
    "            all_t.append(t); all_o.append(o)\n",
    "        print('-'*50 + '\\n')\n",
    "    else:\n",
    "        print('-'*50)\n",
    "        for i in idx:\n",
    "            t, o = trg[i, 1:].tolist(), output[i, :-1].tolist()\n",
    "            t, o = tokenizer.decode(t), tokenizer.decode(o)\n",
    "            t, o = ' '.join(t.split()), ' '.join(o.split())\n",
    "            print('gt  : {}'.format(t))\n",
    "            print('pred: {}\\n'.format(o))\n",
    "            all_t.append(t); all_o.append(o)\n",
    "        print('-'*50 + '\\n')\n",
    "    return all_t, all_o\n",
    "\n",
    "\n",
    "\n",
    "def bleu_score(ref, pred, weights):\n",
    "    print('bleu_score')\n",
    "    print(type(ref), ref)\n",
    "    print(type(pred), pred)\n",
    "    print(type(weights), weights)\n",
    "    return corpus_bleu(ref, pred, weights)\n",
    "\n",
    "\n",
    "def nist_score(ref, pred, n):\n",
    "    return corpus_nist(ref, pred, n)\n",
    "\n",
    "\n",
    "def cal_scores(ref, pred, type, n_gram):\n",
    "    assert type in ['bleu', 'nist']\n",
    "    if type == 'bleu':\n",
    "        wts = (1/n_gram,) * n_gram\n",
    "        print('wts is', wts)\n",
    "        return bleu_score(ref, pred, wts)\n",
    "    \n",
    "    print('bbbbb')\n",
    "    return nist_score(ref, pred, n_gram)\n",
    "\n",
    "\n",
    "\n",
    "def tensor2list(ref, pred, tokenizer):\n",
    "    ref, pred = torch.cat(ref, dim=0)[:, 1:], torch.cat(pred, dim=0)[:, :-1]\n",
    "    ref = [[tokenizer.decode(ref[i].tolist()).split()] for i in range(ref.size(0))]\n",
    "    pred = [tokenizer.decode(torch.argmax(pred[i], dim=1).tolist()).split() for i in range(pred.size(0))]\n",
    "    return ref, pred\n",
    "\n",
    "\n",
    "def collect_all_pairs(caption_file):\n",
    "    captions = pd.read_csv(caption_file)\n",
    "    all_pairs = [[img, preprocessing(cap.lower())] for img, cap in zip(captions['image'], captions['caption'])]\n",
    "    return all_pairs\n",
    "    \n",
    "\n",
    "def make_dataset_ids(total_l, valset_l):\n",
    "    random.seed(999)\n",
    "    all_id = list(range(total_l))\n",
    "    trainset_id = random.sample(all_id, total_l - valset_l)\n",
    "    valset_id = list(set(all_id) - set(trainset_id))\n",
    "    return trainset_id, valset_id\n",
    "\n",
    "\n",
    "def preprocessing(s):\n",
    "    s = re.sub('[#$%&()*+\\-/:;<=>@\\[\\]^_`{|}~\\'\".,?!]', '', s).lower()\n",
    "    s = ' '.join(s.split())\n",
    "    return s\n",
    "\n",
    "\n",
    "def topk_accuracy(pred, target, k, eos_token_id):\n",
    "    pred, target = pred.detach().cpu(), target.detach().cpu()\n",
    "\n",
    "    total_correct = 0\n",
    "    batch_size = 0\n",
    "    for i in range(target.size(0)):\n",
    "        l = target[i].tolist().index(eos_token_id)\n",
    "        _, idx = torch.topk(pred[i, :l], k, dim=1)\n",
    "        correct = idx.eq(target[i, :l].unsqueeze(1).expand_as(idx))\n",
    "        total_correct += correct.view(-1).float().sum()\n",
    "        batch_size += l\n",
    "    return total_correct.item() * (100.0 / batch_size)\n",
    "\n",
    "\n",
    "def save_figures(img_id, gt, pred, save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    for i, (img, g, p) in enumerate(zip(img_id, gt, pred)):\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "        ax.axes.xaxis.set_visible(False)\n",
    "        ax.axes.yaxis.set_visible(False)\n",
    "        img = plt.imread(img)\n",
    "        h, w, _ = img.shape\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.text(w/2, h+20, 'gt: '+g, horizontalalignment='center')\n",
    "        plt.text(w/2, h+40, 'pred: '+p, horizontalalignment='center')\n",
    "        plt.savefig(save_path + 'result_' + str(i+1) + '.jpg')\n",
    "\n",
    "\n",
    "def save_attn_figures(img_id, attn_img, pred, save_path, trans, enc_hidden_size):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    mybox={'facecolor':'w','boxstyle':'square','alpha':1}\n",
    "\n",
    "    for i, (img, attn, p) in enumerate(zip(img_id, attn_img, pred)):\n",
    "        img = trans(Image.open(img)).permute(1, 2, 0)\n",
    "        attn = attn.view(enc_hidden_size, enc_hidden_size, -1)\n",
    "        p = p.split()\n",
    "\n",
    "        plt.figure(figsize=(4*3, math.ceil(len(p)/4)*3))\n",
    "        for j in range(attn.size(-1)):\n",
    "            score = skimage.transform.pyramid_expand(attn[:, :, j].numpy(), upscale=18, sigma=8)\n",
    "            plt.subplot(math.ceil(len(p)/4), 4, j+1)\n",
    "            ax = plt.gca()\n",
    "            ax.axes.xaxis.set_visible(False)\n",
    "            ax.axes.yaxis.set_visible(False)\n",
    "            plt.imshow(img)\n",
    "            plt.imshow(score, cmap='gray', alpha=0.7)\n",
    "            plt.text(5, 15, p[j], bbox=mybox)\n",
    "        plt.savefig(save_path + 'result_attn_' + str(i+1) + '.jpg')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
